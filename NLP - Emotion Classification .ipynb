{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246a4932-7dce-4e2c-b053-e12253e9a1f4",
   "metadata": {},
   "source": [
    " <h1 style=\"color:blue\">NLP - Emotion Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01555d74-552d-4fca-bc78-fb76fd9b56c5",
   "metadata": {},
   "source": [
    "<h3 style>\n",
    "    \n",
    "    1. Loading and Preprocessing\n",
    "    2. Feature Extraction\n",
    "    3. Model Development\n",
    "    4. Model Comparison\n",
    "</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f1cf7-682c-437b-b65a-9b86a71330b5",
   "metadata": {},
   "source": [
    " <h4  style=\"color:green;\"> 1. Loading and Preprocessing </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b1d64a-3a4f-4584-aff1-a31cdf65adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73e63d8-920e-450e-93d0-ffdeeef7fcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Comment Emotion\n",
      "0     i seriously hate one subject to death but now ...    fear\n",
      "1                    im so full of life i feel appalled   anger\n",
      "2     i sit here to write i start to dig out my feel...    fear\n",
      "3     ive been really angry with r and i feel like a...     joy\n",
      "4     i feel suspicious if there is no one outside l...    fear\n",
      "...                                                 ...     ...\n",
      "5932                 i begun to feel distressed for you    fear\n",
      "5933  i left feeling annoyed and angry thinking that...   anger\n",
      "5934  i were to ever get married i d have everything...     joy\n",
      "5935  i feel reluctant in applying there because i w...    fear\n",
      "5936  i just wanted to apologize to you because i fe...   anger\n",
      "\n",
      "[5937 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"nlp_dataset.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0397b1c-048f-403c-b671-76bdd2c624ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598a9330-51a0-4d22-9fd4-e5d3ecc7ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5937 entries, 0 to 5936\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Comment  5937 non-null   object\n",
      " 1   Emotion  5937 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 92.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eab86c0-3e54-4029-b7b0-38d461cd807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc5993a1-cb6a-4e06-9418-c7bd1ab8bde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5927</th>\n",
       "      <td>i have never done anything to make her cry or ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>i feel angry because i have led myself to lead...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>i mean weve been friends for a long time and t...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>i think we often feel this way about planting ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>i have lost touch with the things that i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "5927  i have never done anything to make her cry or ...    fear\n",
       "5928  i feel angry because i have led myself to lead...   anger\n",
       "5929  i mean weve been friends for a long time and t...   anger\n",
       "5930  i think we often feel this way about planting ...    fear\n",
       "5931  i have lost touch with the things that i feel ...     joy\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the last few rows of the dataset\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31f9b05-e3cf-4d78-b164-0a8b544008a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Comment Emotion\n",
      "count                                               5937    5937\n",
      "unique                                              5934       3\n",
      "top     i feel like a tortured artist when i talk to her   anger\n",
      "freq                                                   2    2000\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04079f9-99ba-447e-9f2a-3f74aa3cbd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Comment', 'Emotion'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abba733e-6bf8-4772-880d-ee9971c0dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Comment    0\n",
      "Emotion    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33bacb1c-4daa-42f9-860e-a84b46c285e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5314d5ce-2f14-49ca-873e-b76620b68899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and numbers\n",
    "cleaned_text = []\n",
    "for text in df['Comment']:\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    cleaned_text.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8d6eee-bd8b-4223-9066-c0d81c007c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "cleaned_text = [text.lower() for text in cleaned_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc48e867-425c-425a-aaf5-bcbf21b05db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenized_text = [word_tokenize(text) for text in cleaned_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dfc047b-1fa2-4211-b826-ce2be8466721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = []\n",
    "for tokens in tokenized_text:\n",
    "    filtered_text.append([word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f975fcf-1e71-4763-9285-13f4a7d9001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                 Comment Emotion  \\\n",
      "0     i seriously hate one subject to death but now ...    fear   \n",
      "1                    im so full of life i feel appalled   anger   \n",
      "2     i sit here to write i start to dig out my feel...    fear   \n",
      "3     ive been really angry with r and i feel like a...     joy   \n",
      "4     i feel suspicious if there is no one outside l...    fear   \n",
      "...                                                 ...     ...   \n",
      "5932                 i begun to feel distressed for you    fear   \n",
      "5933  i left feeling annoyed and angry thinking that...   anger   \n",
      "5934  i were to ever get married i d have everything...     joy   \n",
      "5935  i feel reluctant in applying there because i w...    fear   \n",
      "5936  i just wanted to apologize to you because i fe...   anger   \n",
      "\n",
      "                                           cleaned_text  \n",
      "0     seriously hate one subject death feel reluctan...  \n",
      "1                            im full life feel appalled  \n",
      "2     sit write start dig feelings think afraid acce...  \n",
      "3     ive really angry r feel like idiot trusting fi...  \n",
      "4     feel suspicious one outside like rapture happe...  \n",
      "...                                                 ...  \n",
      "5932                              begun feel distressed  \n",
      "5933  left feeling annoyed angry thinking center stu...  \n",
      "5934  ever get married everything ready offer got to...  \n",
      "5935  feel reluctant applying want able find company...  \n",
      "5936         wanted apologize feel like heartless bitch  \n",
      "\n",
      "[5937 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "final_text = [' '.join(tokens) for tokens in filtered_text]\n",
    "\n",
    "# Add cleaned text to the dataframe\n",
    "df['cleaned_text'] = final_text\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b780b-4edb-4e6c-9f0f-870a6ba9284f",
   "metadata": {},
   "source": [
    "<h4>Preprocessing Techniques and Their Impact on Model Performance</h4>\n",
    "Reduces noise in the text data, making it easier for models to focus on meaningful words.\n",
    "Improve Consistency: Ensure uniform representation of words.\n",
    "Enhance Feature Quality: Provide cleaner, more meaningful features for the models to learn from,\n",
    "leading to better performance in text classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203101cd-d5e0-40b6-a2b9-0bee4204599c",
   "metadata": {},
   "source": [
    "<h4  style=\"color:green;\">2.Feature Extraction</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f6cb876-6622-42be-b9fd-8924bb300e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = vectorizer.fit_transform(df['cleaned_text']).toarray()\n",
    "\n",
    "# Extract target variable\n",
    "y = df['Emotion']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ddbcf-be61-480f-9a06-146936b39227",
   "metadata": {},
   "source": [
    "Feature Representation: Text data is transformed into numerical features that machine learning algorithms can process.\n",
    "Weighting Important Terms: Terms that are more relevant to the document (higher TF) and less common across documents (higher IDF) are given higher \n",
    "weights.Dimensionality Reduction: Limiting the number of features (e.g., top 1000 terms) helps in reducing the complexity and improving the \n",
    "efficiency of the model.By using TF-IDF, we create a feature set that captures the importance of terms in the context of individual documents and \n",
    "the entire dataset, leading to more accurateand meaningful numerical representations for text classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345f2a5-a3ef-4b26-bb40-58448c12a3dd",
   "metadata": {},
   "source": [
    "<h4  style=\"color:green;\">3 Model Development</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9045a2f1-4260-4aa2-b4c3-3d0241eacffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9158249158249159\n",
      "Naive Bayes F1-Score:  0.9158756487178424\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\",accuracy_nb)\n",
    "print(\"Naive Bayes F1-Score: \",f1_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c8f2153-55b4-4000-a5df-7ceb44e1961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy: 0.9436026936026936\n",
      "Support Vector Machine F1-Score:  0.9436022027688145\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "print(\"Support Vector Machine Accuracy:\",accuracy_svm)\n",
    "print(\"Support Vector Machine F1-Score: \",f1_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a913f90-9db9-4c7f-9462-d4ab7e49e1a8",
   "metadata": {},
   "source": [
    "<h4  style=\"color:green;\">4.Model Comparison</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad24f4f9-563f-46c3-ad42-3db7aaf619a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Accuracy  F1-Score\n",
      "0             Naive Bayes  0.915825  0.915876\n",
      "1  Support Vector Machine  0.943603  0.943602\n"
     ]
    }
   ],
   "source": [
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'Support Vector Machine'],\n",
    "    'Accuracy': [accuracy_nb, accuracy_svm],\n",
    "    'F1-Score': [f1_nb, f1_svm]})\n",
    "print(model_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72be98-9519-44d3-a384-4667e8b9ac4e",
   "metadata": {},
   "source": [
    "<h3>Chosen Models and Their Suitability for Emotion Classification</h3>\n",
    "\n",
    "Naive Bayes\n",
    "\n",
    "Model Description:\n",
    "Naive Bayes is a probabilistic classifier based on Bayes' theorem, assuming independence between features.\n",
    "\n",
    "Text Data: Works well with text data where the assumption of feature independence is often reasonable.\n",
    "\n",
    "Speed and Efficiency: Fast to train and predict, making it suitable for large datasets.\n",
    "\n",
    "Performance: Often performs well with sparse data, which is common in text classification tasks like emotion classification.\n",
    "\n",
    "Support Vector Machine (SVM)\n",
    "\n",
    "Model Description:\n",
    "SVM is a powerful classifier that finds the hyperplane that best separates data into classes.\n",
    "\n",
    "High Dimensional Spaces: Effective in high-dimensional spaces and with sparse data, typical of text features.\n",
    "\n",
    "Margin Maximization: Focuses on maximizing the margin between classes, which can lead to better generalization on unseen data.\n",
    "\n",
    "Versatility: Can handle non-linear classification through the use of kernel functions, making it adaptable to complex relationships in the data.\n",
    "\n",
    "Naive Bayes is suitable for emotion classification due to its simplicity, efficiency, and good performance with text data.\n",
    "\n",
    "SVM is suitable because of its effectiveness in high-dimensional and sparse datasets, and its strong generalization capabilities.in this model SVM have high accuracy and f1-score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
